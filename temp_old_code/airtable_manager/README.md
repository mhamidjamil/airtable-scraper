# Airtable Pattern Upload - Complete Project

## ğŸ“‚ **Project Structure**

```
airtable_manager/
â”œâ”€â”€ biome_extractor.py         # Extracts patterns from BIOME folder
â”œâ”€â”€ pattern_document_processor.py  # Processes Google Docs
â”œâ”€â”€ prepare_airtable_data.py   # CSV generation (deprecated)
â”‚
â”œâ”€â”€ airtable_api_upload/       # âœ… ACTIVE: API upload system
â”‚   â”œâ”€â”€ generate_json.py        # Generate JSON from extraction
â”‚   â”œâ”€â”€ upload_to_airtable.py   # Main upload script
â”‚   â”œâ”€â”€ fix_variation_links.py  # Fix variation â†’ pattern links
â”‚   â”œâ”€â”€ verify_data.py          # Verify Airtable data
â”‚   â”œâ”€â”€ inspect_schema.py       # Read Airtable schema
â”‚   â”œâ”€â”€ config.json             # API credentials (gitignored)
â”‚   â”œâ”€â”€ json_data/              # Generated JSON files
â”‚   â”œâ”€â”€ logs/                   # Upload logs  
â”‚   â””â”€â”€ id_mappings/            # ID mapping files
â”‚
â”œâ”€â”€ docs/                       # All documentation
â”‚   â”œâ”€â”€ API_UPLOAD_COMPLETE.md  # API system overview
â”‚   â”œâ”€â”€ QUICK_START.md          # Fast setup guide
â”‚   â”œâ”€â”€ README.md               # Detailed API setup
â”‚   â”œâ”€â”€ AIRTABLE_IMPORT_STRATEGY_FINAL.md  # CSV strategy
â”‚   â”œâ”€â”€ QUICK_START_IMPORT_GUIDE.md        # CSV guide
â”‚   â””â”€â”€ (other analysis docs)
â”‚
â”œâ”€â”€ data_output/                # Extraction outputs
â””â”€â”€ csv_output/                 # CSV files (deprecated)
```

---

## ğŸš€ **Quick Start**

### **1. Extract Data from Google Docs**
```bash
cd airtable_manager
python biome_extractor.py
```
**Output:** `data_output/biome_extracted_YYYYMMDD_HHMMSS.json`

### **2. Generate API Upload JSONs**
```bash
cd airtable_api_upload
python generate_json.py
```
**Output:** 5 JSON files in `json_data/`
- lenses.json (5 records)
- sources.json (50 records)
- metas.json (5 records)
- variations.json (46 records)
- patterns.json (50 records)

### **3. Upload to Airtable**
```bash
# Setup config
cp config.json.template config.json
# Edit config.json with your API token and base ID

# Upload
python upload_to_airtable.py
```

### **4. Fix Variation Links (if needed)**
```bash
python fix_variation_links.py
```

### **5. Verify Upload**
```bash
python verify_data.py
```

---

## âœ… **What Was Uploaded**

### **Current Airtable State:**
- âœ… 5 Lenses (all linked)
- âœ… 50 Sources (all linked)
- âœ… 5 METAS
- âœ… 46 Variations (all linked to 10 patterns)
- âœ… 50 Patterns (with links to lenses, sources, variations)

**Note:** Only 10 of 50 patterns have variations:
- Pattern 1: 10 variations
- Pattern 11: 10 variations
- Pattern 21: 8 variations
- Pattern 31: 8 variations
- Pattern 41: 10 variations
- **Other 40 patterns:** No variations

---

## ğŸ“– **Documentation**

### **For API Upload:**
- `docs/QUICK_START.md` - Fast 3-step setup
- `docs/README.md` - Detailed setup with troubleshooting
- `docs/API_UPLOAD_COMPLETE.md` - Complete system overview

### **For CSV Upload (Deprecated):**
- `docs/AIRTABLE_IMPORT_STRATEGY_FINAL.md` - CSV strategy
- `docs/QUICK_START_IMPORT_GUIDE.md` - CSV quick guide

---

## ğŸ”‘ **Configuration**

### **Required Credentials** (`config.json`):
```json
{
  "airtable_token": "patXXXXX...",
  "base_id": "appXXXXX..."
}
```

**Get credentials:** See `docs/QUICK_START.md`

---

## ğŸ› ï¸ **Utilities**

### **Inspect Airtable Schema:**
```bash
python inspect_schema.py
```
Shows all tables and fields in your Airtable base.

### **Verify Upload:**
```bash
python verify_data.py
```
Checks if variations are linked to patterns.

### **Fix Variation Links:**
```bash
python fix_variation_links.py
```
Updates variations with pattern_reference links.

---

## ğŸ“ **Workflow**

1. **Extract** â†’ Run `biome_extractor.py`
2. **Generate JSON** â†’ Run `generate_json.py`
3. **Upload** â†’ Run `upload_to_airtable.py`
4. **Fix Links** â†’ Run `fix_variation_links.py`
5. **Verify** â†’ Run `verify_data.py`

---

## ğŸ¯ **Key Features**

- âœ… Batch upload (10 records per batch)
- âœ… ID mapping system for relationships
- âœ… Automatic schema detection
- âœ… Comprehensive logging
- âœ… Error handling & retry logic
- âœ… Rate limiting (5 req/sec)
- âœ… UTF-8 encoding support

---

## ğŸ“Š **Data Flow**

```
Google Docs (BIOME folder)
    â†“
biome_extractor.py
    â†“
biome_extracted_*.json
    â†“
generate_json.py
    â†“
5 JSON files (lenses, sources, metas, variations, patterns)
    â†“
upload_to_airtable.py
    â†“
Airtable (Lenses â†’ Sources â†’ Metas â†’ Variations â†’ Patterns)
    â†“
fix_variation_links.py
    â†“
Verified in Airtable âœ…
```

---

## ğŸ› **Troubleshooting**

**"Unknown field name" error:**
â†’ Run `inspect_schema.py` to see actual Airtable fields
â†’ Upload script auto-adapts to your schema

**Variations not linked:**
â†’ Run `fix_variation_links.py`

**Unicode errors:**
â†’ All scripts use UTF-8 encoding

**Rate limit errors:**
â†’ Script auto-waits 0.2s between requests

---

## ğŸ“¦ **Dependencies**

```bash
pip install requests
```

---

## ğŸ™Œ **Current Status**

âœ… **Complete and Production-Ready!**
- All 5 tables uploaded
- All relationships linked
- Documentation complete
- Project organized

**Last Upload:** Check `logs/` folder for timestamp

---

For detailed setup instructions, see **`docs/QUICK_START.md`**
